{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b059d333-5354-4cfd-911f-512858177986",
   "metadata": {},
   "source": [
    "**trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1965bfd3-cb42-49af-8a6e-fcb6879b07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from threading import Thread, Lock\n",
    "import time\n",
    "import numpy as np\n",
    "import dlib\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6be3c0ff-b63c-4516-a987-3dcf63a6146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RTSP_URL = \"rtsp://wellantmilieu@gmail.com:q8oEZQC!W$8d@192.168.178.22:554/stream2\"\n",
    "#cap = cv2.VideoCapture(1) #of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af0eed69-fc43-485c-831c-ae5522fe2df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"datasets\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8934f67e-79b6-47d1-89d3-eb89502b33f7",
   "metadata": {},
   "source": [
    "### model trainer met LBPH (Local Binary Pattern Histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3699fa72-cdfa-49d0-a124-be6cb1d80753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b8f999e2ee4494ba49a01fd97a2598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Selecteer Naam:', options=('Arend', 'Bobby', 'Joost', 'Marieke_2', 'PJ', 'Robert', 'Unkn‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef184f597ba442c5b31b5e81c49f67ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Train Model', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed32620acb84e5b9e412e2e413afcd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ophalen van beschikbare dataset-mappen\n",
    "available_datasets = [d for d in os.listdir(BASE_DIR) if os.path.isdir(os.path.join(BASE_DIR, d))]\n",
    "\n",
    "# Dropdown-menu voor dataset-selectie\n",
    "dataset_dropdown = widgets.Dropdown(\n",
    "    options=available_datasets,\n",
    "    description=\"Selecteer Naam:\"\n",
    ")\n",
    "train_button = widgets.Button(description=\"Train Model\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Weergave in Notebook\n",
    "display(dataset_dropdown, train_button, output)\n",
    "\n",
    "# **üìå Functie om een afbeelding te verbeteren**\n",
    "def preprocess_image(img):\n",
    "    \"\"\" Zorgt voor betere herkenning door bewerking van afbeeldingen \"\"\"\n",
    "    img = cv2.equalizeHist(img)  # ‚úÖ Helderheid normaliseren\n",
    "    img = cv2.GaussianBlur(img, (3, 3), 0)  # ‚úÖ Ruis verminderen\n",
    "    return img\n",
    "\n",
    "# **üìå Data augmentatie toepassen**\n",
    "def augment_image(img):\n",
    "    \"\"\" Voegt variatie toe aan trainingsdata \"\"\"\n",
    "    augmented_images = []\n",
    "\n",
    "    # Oorspronkelijke afbeelding\n",
    "    augmented_images.append(img)\n",
    "\n",
    "    # Horizontale spiegeling\n",
    "    augmented_images.append(cv2.flip(img, 1))\n",
    "\n",
    "    # Kleine rotaties\n",
    "    for angle in [-10, 10]:  \n",
    "        rows, cols = img.shape\n",
    "        M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "        rotated = cv2.warpAffine(img, M, (cols, rows))\n",
    "        augmented_images.append(rotated)\n",
    "\n",
    "    # Lichte contrastwijzigingen\n",
    "    alpha = random.uniform(0.8, 1.2)  # Contrast (0.8-1.2)\n",
    "    beta = random.randint(-20, 20)  # Helderheid (-20 tot 20)\n",
    "    contrast = cv2.convertScaleAbs(img, alpha=alpha, beta=beta)\n",
    "    augmented_images.append(contrast)\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "# **üìå Train het model met betere data**\n",
    "def train_model(_):\n",
    "    selected_name = dataset_dropdown.value\n",
    "    if not selected_name:\n",
    "        with output:\n",
    "            print(\"Selecteer een dataset om te trainen.\")\n",
    "        return\n",
    "\n",
    "    PROCESSED_DIR = os.path.join(BASE_DIR, selected_name, \"processed_faces\")\n",
    "    MODEL_PATH = os.path.join(BASE_DIR, selected_name, f\"face_model_{selected_name}.yml\")\n",
    "\n",
    "    # Controleren of er gezichten beschikbaar zijn\n",
    "    image_files = [f for f in os.listdir(PROCESSED_DIR) if f.endswith(\".jpg\")]\n",
    "    if not image_files:\n",
    "        with output:\n",
    "            print(f\"Geen gezichten gevonden in {PROCESSED_DIR}, training geannuleerd.\")\n",
    "        return\n",
    "\n",
    "    # Gegevens en labels verzamelen\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_dict = {name: idx for idx, name in enumerate(available_datasets)}  # ‚úÖ Unieke labels per persoon\n",
    "\n",
    "    for filename in image_files:\n",
    "        img_path = os.path.join(PROCESSED_DIR, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if img is None:\n",
    "            with output:\n",
    "                print(f\"‚ö†Ô∏è Kan afbeelding {filename} niet laden, overslaan.\")\n",
    "            continue\n",
    "\n",
    "        # **‚úÖ Verbeter de afbeelding en pas data augmentation toe**\n",
    "        img = preprocess_image(img)\n",
    "        augmented_imgs = augment_image(img)\n",
    "\n",
    "        for aug_img in augmented_imgs:\n",
    "            aug_img_resized = cv2.resize(aug_img, (200, 200))\n",
    "            images.append(aug_img_resized)\n",
    "            labels.append(label_dict[selected_name])\n",
    "\n",
    "    # **üöÄ Check de datasetgrootte**\n",
    "    print(f\"üìä Totaal {len(images)} beelden na augmentatie.\")\n",
    "\n",
    "    # **üìå Model trainen**\n",
    "    model = cv2.face.LBPHFaceRecognizer_create()\n",
    "    model.train(np.array(images, dtype=np.uint8), np.array(labels, dtype=np.int32))\n",
    "\n",
    "    # **üìÇ Opslaan in `datasets/<naam>/`**\n",
    "    model.save(MODEL_PATH)\n",
    "\n",
    "    with output:\n",
    "        print(f\"‚úÖ Model getraind en opgeslagen als {MODEL_PATH} met {len(images)} beelden.\")\n",
    "\n",
    "# Koppel knop aan functie\n",
    "train_button.on_click(train_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88713e67-3ae5-4926-a664-772c72fc384f",
   "metadata": {},
   "source": [
    "### modeltrainer met CCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "881c552d-1c84-4860-b3b6-fd74b90adc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c3908274ca4e9bbf8131545a18cf3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Train Model', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0416168fe71c483dafd9c0efbe5476c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_PATH = \"face_recognition_modelv2.h5\"\n",
    "LABEL_PATH = \"label_mapping.npy\"\n",
    "\n",
    "# Ophalen van beschikbare dataset-mappen\n",
    "available_datasets = [d for d in os.listdir(BASE_DIR) if os.path.isdir(os.path.join(BASE_DIR, d, \"processed_faces\"))]\n",
    "\n",
    "# Train-knop en output venster\n",
    "train_button = widgets.Button(description=\"Train Model\")\n",
    "output = widgets.Output()\n",
    "display(train_button, output)\n",
    "\n",
    "def train_model(_):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_dict = {}\n",
    "\n",
    "    # Verzamel ALLE gezichten per persoon (processed_faces)\n",
    "    person_images = {}\n",
    "    \n",
    "    for idx, person in enumerate(available_datasets):\n",
    "        person_path = os.path.join(BASE_DIR, person, \"processed_faces\")\n",
    "        image_files = [os.path.join(person_path, f) for f in os.listdir(person_path) if f.endswith(\".jpg\")]\n",
    "\n",
    "        if len(image_files) < 5:  # Minimaal 5 afbeeldingen vereist\n",
    "            with output:\n",
    "                print(f\"‚ùå Onvoldoende foto's voor {person}, overslaan.\")\n",
    "            continue\n",
    "        \n",
    "        label_dict[person] = idx  # Koppel naam aan label index\n",
    "        person_images[idx] = image_files\n",
    "\n",
    "    if not person_images:\n",
    "        with output:\n",
    "            print(\"‚ùå Geen geldige afbeeldingen gevonden voor training.\")\n",
    "        return\n",
    "\n",
    "    # **Zorg dat alle labels evenveel afbeeldingen hebben**\n",
    "    min_images = min(len(imgs) for imgs in person_images.values())\n",
    "    balanced_images = []\n",
    "    balanced_labels = []\n",
    "    \n",
    "    for label, image_files in person_images.items():\n",
    "        selected_files = np.random.choice(image_files, min_images, replace=False)  # Random selecteren\n",
    "        for img_path in selected_files:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_resized = cv2.resize(img, (100, 100))\n",
    "            balanced_images.append(img_resized)\n",
    "            balanced_labels.append(label)\n",
    "\n",
    "    # **Converteer naar numpy arrays en normaliseer**\n",
    "    images = np.array(balanced_images, dtype=\"float32\") / 255.0\n",
    "    labels = np.array(balanced_labels, dtype=\"int32\")\n",
    "\n",
    "    # **Gebruik Data Augmentation**\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    for img, label in zip(images, labels):\n",
    "        img = np.expand_dims(img, axis=0)  # Expand dims voor ImageDataGenerator\n",
    "        augment_iter = datagen.flow(img, batch_size=1)\n",
    "        \n",
    "        for _ in range(3):  # Voeg 3 augmented versies toe per afbeelding\n",
    "            augmented_img = next(augment_iter)[0]\n",
    "            augmented_images.append(augmented_img)\n",
    "            augmented_labels.append(label)\n",
    "\n",
    "    # Voeg augmented data toe aan dataset\n",
    "    images = np.concatenate([images, np.array(augmented_images)], axis=0)\n",
    "    labels = np.concatenate([labels, np.array(augmented_labels)], axis=0)\n",
    "\n",
    "    # **Shuffle de dataset om bias te voorkomen**\n",
    "    images, labels = shuffle(images, labels, random_state=42)\n",
    "\n",
    "    # **Verbeterd model met Dropout**\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),  # Voorkomt overfitting\n",
    "        Dense(len(label_dict), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(images, labels, epochs=15, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    model.save(MODEL_PATH)\n",
    "    np.save(LABEL_PATH, label_dict)\n",
    "\n",
    "    with output:\n",
    "        print(f\"‚úÖ Model opgeslagen als {MODEL_PATH} en labels als {LABEL_PATH}\")\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        print(\"Aantal afbeeldingen per label:\", dict(zip(unique, counts)))\n",
    "        print(\"Label mapping:\", label_dict)\n",
    "\n",
    "train_button.on_click(train_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df05725e-b2bf-4179-957b-1a7987f2c988",
   "metadata": {},
   "source": [
    "### update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f555dbd-70a5-42b8-8f0e-3476e5615cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paden voor datasets, model en labels\n",
    "BASE_DIR = \"datasets\"\n",
    "MODEL_PATH = \"face_recognition_model_git.h5\"\n",
    "LABEL_PATH = \"label_mapping_git.npy\"\n",
    "\n",
    "# Ophalen van beschikbare dataset-mappen die een \"processed_faces\" submap hebben\n",
    "available_datasets = [d for d in os.listdir(BASE_DIR) if os.path.isdir(os.path.join(BASE_DIR, d, \"processed_faces\"))]\n",
    "\n",
    "# Widgets: train-knop en output-venster\n",
    "train_button = widgets.Button(description=\"Train Model\")\n",
    "output = widgets.Output()\n",
    "display(train_button, output)\n",
    "\n",
    "def train_model(_):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(\"Start training...\")\n",
    "        \n",
    "    images = []\n",
    "    labels = []\n",
    "    label_dict = {}  # mapping: label_index -> persoon\n",
    "    person_images = {}\n",
    "\n",
    "    # Bouw de labelmapping en verzamel paden naar afbeeldingen per persoon\n",
    "    for idx, person in enumerate(available_datasets):\n",
    "        person_path = os.path.join(BASE_DIR, person, \"processed_faces\")\n",
    "        image_files = [os.path.join(person_path, f) for f in os.listdir(person_path) if f.endswith(\".jpg\")]\n",
    "        \n",
    "        if len(image_files) < 5:  # minimaal 5 afbeeldingen vereist\n",
    "            with output:\n",
    "                print(f\"‚ùå Onvoldoende foto's voor {person}, overslaan.\")\n",
    "            continue\n",
    "        \n",
    "        label_dict[idx] = person  # mapping van index naar persoonsnaam\n",
    "        person_images[idx] = image_files\n",
    "\n",
    "    if not person_images:\n",
    "        with output:\n",
    "            print(\"‚ùå Geen geldige afbeeldingen gevonden voor training.\")\n",
    "        return\n",
    "\n",
    "    # Zorg dat alle labels evenveel afbeeldingen hebben\n",
    "    min_images = min(len(imgs) for imgs in person_images.values())\n",
    "    balanced_images = []\n",
    "    balanced_labels = []\n",
    "    \n",
    "    for label, image_files in person_images.items():\n",
    "        selected_files = np.random.choice(image_files, min_images, replace=False)\n",
    "        for img_path in selected_files:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_resized = cv2.resize(img, (100, 100))\n",
    "            balanced_images.append(img_resized)\n",
    "            balanced_labels.append(label)\n",
    "\n",
    "    # Converteer naar numpy arrays en normaliseer\n",
    "    images = np.array(balanced_images, dtype=\"float32\") / 255.0\n",
    "    labels = np.array(balanced_labels, dtype=\"int32\")\n",
    "\n",
    "    # Data Augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    for img, label in zip(images, labels):\n",
    "        img_expanded = np.expand_dims(img, axis=0)\n",
    "        augment_iter = datagen.flow(img_expanded, batch_size=1)\n",
    "        for _ in range(3):  # 3 augmented versies per afbeelding\n",
    "            augmented_img = next(augment_iter)[0]\n",
    "            augmented_images.append(augmented_img)\n",
    "            augmented_labels.append(label)\n",
    "\n",
    "    images = np.concatenate([images, np.array(augmented_images)], axis=0)\n",
    "    labels = np.concatenate([labels, np.array(augmented_labels)], axis=0)\n",
    "\n",
    "    # Shuffle de dataset\n",
    "    images, labels = shuffle(images, labels, random_state=42)\n",
    "\n",
    "    # Bouw het model met dropout ter voorkoming van overfitting\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(len(label_dict), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(images, labels, epochs=15, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    # Sla het model en de labelmapping op\n",
    "    model.save(MODEL_PATH)\n",
    "    np.save(LABEL_PATH, label_dict)\n",
    "\n",
    "    with output:\n",
    "        print(f\"‚úÖ Model opgeslagen als {MODEL_PATH} en labels als {LABEL_PATH}\")\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        print(\"Aantal afbeeldingen per label:\", dict(zip(unique, counts)))\n",
    "        print(\"Label mapping:\", label_dict)\n",
    "\n",
    "train_button.on_click(train_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
