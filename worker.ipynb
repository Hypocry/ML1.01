{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc90278b-27c7-4ab2-af33-f3c425c76010",
   "metadata": {},
   "source": [
    "**worker**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac052cf-42e7-41be-a2f7-029dd2464533",
   "metadata": {},
   "source": [
    "## Live Gezichtsherkenning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00f727-640e-4553-a0f1-7f2d4c3bd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RTSP_URL = \"jouw_TRSP-datastream\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1783a62-2802-4e6e-bdee-ebf6b1f3e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from threading import Thread, Lock\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32883c3f-43f4-43c5-8af1-8fb7cb619f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../dataset\" # of je eigen locatie\n",
    "# open de camera\n",
    "cap = cv2.VideoCapture(1)\n",
    "lock = Lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc0f700-6241-43f4-90ac-75f0d3dccb0a",
   "metadata": {},
   "source": [
    "## inladen LBPH-modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f95c87-9219-4c28-9f12-6b97ace52471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV haarcascade gezichtsdetectie\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# **Automatisch alle modellen laden**\n",
    "models = {}\n",
    "for person in os.listdir(BASE_DIR):\n",
    "    model_path = os.path.join(BASE_DIR, person, f\"face_model_{person}.yml\")\n",
    "    if os.path.exists(model_path):\n",
    "        model = cv2.face.LBPHFaceRecognizer_create()\n",
    "        model.read(model_path)\n",
    "        models[person] = model\n",
    "        print(f\"Model geladen voor {person}\")\n",
    "\n",
    "if not models:\n",
    "    print(\"Geen modellen correct geladen. Train eerst een model.\")\n",
    "\n",
    "# Widgets voor de live feed\n",
    "image_widget = widgets.Image(format='jpeg')\n",
    "stop_button = widgets.Button(description=\"Stop\")\n",
    "threshold_slider = widgets.IntSlider(value=100, min=50, max=150, step=1, description=\"Threshold\")\n",
    "output = widgets.Output()\n",
    "display(threshold_slider, image_widget, stop_button, output)\n",
    "running = True\n",
    "\n",
    "# Houdt per persoon bij wanneer deze voor het laatst werd gegroet\n",
    "last_greet = {}\n",
    "GREETING_INTERVAL = 10  # seconden\n",
    "\n",
    "# Creëer een queue voor spraakberichten\n",
    "speech_queue = Queue()\n",
    "\n",
    "# Deze worker verwerkt spraakberichten één voor één, zodat engine.runAndWait() niet overlapt\n",
    "def speech_worker():\n",
    "    while running:\n",
    "        try:\n",
    "            message = speech_queue.get(timeout=1)\n",
    "        except Empty:\n",
    "            continue\n",
    "        engine.say(message)\n",
    "        engine.runAndWait()\n",
    "        speech_queue.task_done()\n",
    "\n",
    "speech_thread = Thread(target=speech_worker, daemon=True)\n",
    "speech_thread.start()\n",
    "\n",
    "# **Live gezichtsdetectie en herkenning in een aparte thread**\n",
    "def update_stream():\n",
    "    global running\n",
    "    while running:\n",
    "        with lock:\n",
    "            cap.grab()\n",
    "            ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(\"Geen frame ontvangen. Controleer de camera.\")\n",
    "            break\n",
    "\n",
    "        # Converteer naar grijswaarden voor gezichtsdetectie\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n",
    "        \n",
    "        # Verzamel in deze set alle unieke herkende personen in het huidige frame\n",
    "        current_frame_names = set()\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_img = gray[y:y+h, x:x+w]\n",
    "            face_resized = cv2.resize(face_img, (150, 150))  # Formaat voor herkenning\n",
    "\n",
    "            best_name = \"Unknown\"\n",
    "            best_confidence = float(\"inf\")\n",
    "            confidence_threshold = threshold_slider.value\n",
    "\n",
    "            # Vergelijk gezicht met alle modellen\n",
    "            for name, model in models.items():\n",
    "                label, confidence = model.predict(face_resized)\n",
    "                if confidence < best_confidence:\n",
    "                    best_confidence = confidence\n",
    "                    best_name = name\n",
    "            \n",
    "            # Teken groen kader en toon de naam als de confidence onder de threshold zit\n",
    "            if best_confidence < confidence_threshold:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, best_name, (x, y - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                if best_name != \"Unknown\":\n",
    "                    current_frame_names.add(best_name)\n",
    "        \n",
    "        # Voor iedere herkende persoon in dit frame, controleer de GREETING_INTERVAL\n",
    "        current_time = time.time()\n",
    "        for name in current_frame_names:\n",
    "            if name not in last_greet or (current_time - last_greet[name]) > GREETING_INTERVAL:\n",
    "                speech_queue.put(f\"Hello, {name}, welcome home!\")\n",
    "                last_greet[name] = current_time\n",
    "\n",
    "        # Toon live beeld in Jupyter\n",
    "        _, buffer = cv2.imencode('.jpg', frame)\n",
    "        image_widget.value = buffer.tobytes()\n",
    "        time.sleep(0.03)\n",
    "\n",
    "def stop_stream(_):\n",
    "    global running\n",
    "    running = False\n",
    "    with lock:\n",
    "        cap.release()\n",
    "\n",
    "stop_button.on_click(stop_stream)\n",
    "\n",
    "# Start de live stream in een aparte thread\n",
    "thread = Thread(target=update_stream, daemon=True)\n",
    "thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d0e254-c9ca-4793-8a9b-1e71a7c2e255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
